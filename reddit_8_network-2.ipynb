{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import string\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "from string import punctuation\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "import networkx as nx\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "from textblob import TextBlob\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.util import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "matplotlib.rcParams['figure.max_open_warning'] = 1000\n",
    "matplotlib.rcParams['lines.linewidth'] = 1.0\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_ngrams(tokens, rg):\n",
    "    ngrms = []\n",
    "    for i in range(rg[0], rg[1] + 1):\n",
    "        ngrms_aux = [ngrm for ngrm in ngrams(tokens, i)]\n",
    "        ngrms.extend(ngrms_aux)\n",
    "    return ngrms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selected keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "original_keywords = [\"Picard\", \"Kirk\", \"Sulu\", \"Uhura\", \"Spock\", \"McCoy\", \"Bones\", \"Scotty\", \"Chekhov\", \"Crusher\", \"Nurse Chapel\", \"Sarek\", \"Nero\", \"Khan\", \"Data\", \"Pike\", \"Star Trek\", \"Klingon\", \"Vulcan\", \"Romulan\", \"Star fleet\", \"Starship Enterprise\", \"Delta Vega\", \"Earth\", \"Orion\", \"Romulan Narada\", \"Stardate\", \"Transporter beam\", \"Beam me up,\\? Scotty\", \"Kobayashi Maru\", \"Space,\\? The Final Frontier\", \"Energize\", \"Vulcan Salute\", \"Prime Directive\", \"Live long and prosper\", \"LLAP\", \"I'm a doctor,\\? not a\", \"KHAAA\\+N\", \"When you eliminate the impossible,\\? whatever remains,\\? however improbable,\\? must be the truth\", \"Without followers,\\? evil cannot spread\", \"The needs of the many outweigh the needs of the few\", \"Highly illogical\", \"to boldly go where no man has gone before\", \"I'm giving her all she's got,\\? Captain\", \"Nuclear wessels\", \"Set phasers to stun\", \"Resistance is futile\", \"I have been and always shall be your friend\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Picard', 'Kirk', 'Sulu', 'Uhura', 'Spock', 'McCoy', 'Bones', 'Scotty', 'Chekhov', 'Crusher', 'Nurse Chapel', 'Sarek', 'Nero', 'Khan', 'Data', 'Pike', 'Star Trek', 'Klingon', 'Vulcan', 'Romulan', 'Star fleet', 'Starship Enterprise', 'Delta Vega', 'Earth', 'Orion', 'Romulan Narada', 'Stardate', 'Transporter beam', 'Beam me up,\\\\? Scotty', 'Kobayashi Maru', 'Space,\\\\? The Final Frontier', 'Energize', 'Vulcan Salute', 'Prime Directive', 'Live long and prosper', 'LLAP', \"I'm a doctor,\\\\? not a\", 'KHAAA\\\\+N', 'When you eliminate the impossible,\\\\? whatever remains,\\\\? however improbable,\\\\? must be the truth', 'Without followers,\\\\? evil cannot spread', 'The needs of the many outweigh the needs of the few', 'Highly illogical', 'to boldly go where no man has gone before', \"I'm giving her all she's got,\\\\? Captain\", 'Nuclear wessels', 'Set phasers to stun', 'Resistance is futile', 'I have been and always shall be your friend']\n"
     ]
    }
   ],
   "source": [
    "print(original_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ambiguous_keywords = [\n",
    "    'Bones',\n",
    "    'Khan',\n",
    "    'Data',\n",
    "    'Earth',\n",
    "    'Energize',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keywords = list(set(original_keywords).difference(ambiguous_keywords))\n",
    "keywords = [w.replace('\\\\', '').lower() for w in keywords]\n",
    "keywords.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['beam me up,? scotty', 'chekhov', 'crusher', 'delta vega', 'highly illogical', 'i have been and always shall be your friend', \"i'm a doctor,? not a\", \"i'm giving her all she's got,? captain\", 'khaaa+n', 'kirk', 'klingon', 'kobayashi maru', 'live long and prosper', 'llap', 'mccoy', 'nero', 'nuclear wessels', 'nurse chapel', 'orion', 'picard', 'pike', 'prime directive', 'resistance is futile', 'romulan', 'romulan narada', 'sarek', 'scotty', 'set phasers to stun', 'space,? the final frontier', 'spock', 'star fleet', 'star trek', 'stardate', 'starship enterprise', 'sulu', 'the needs of the many outweigh the needs of the few', 'to boldly go where no man has gone before', 'transporter beam', 'uhura', 'vulcan', 'vulcan salute', 'when you eliminate the impossible,? whatever remains,? however improbable,? must be the truth', 'without followers,? evil cannot spread']\n"
     ]
    }
   ],
   "source": [
    "print(keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.92 s, sys: 95.4 ms, total: 4.01 s\n",
      "Wall time: 4.01 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "dtypes = {\n",
    "    'author': str,\n",
    "    'body': str,\n",
    "    'controversiality': int,\n",
    "    'created_utc': pd.tslib.Timestamp,\n",
    "    'distinguished': str,\n",
    "    'downs': str,\n",
    "    'gilded': str,\n",
    "    'id': str,\n",
    "    'name': str,\n",
    "    'parent_id': str,\n",
    "    'score': int,\n",
    "    'subreddit': str,\n",
    "    'ups': str,\n",
    "    'month': pd.tslib.Timestamp,\n",
    "    'year': pd.tslib.Timestamp,\n",
    "}\n",
    "\n",
    "reddit_df = pd.read_csv('user_network.csv', header=0, dtype=dtypes, parse_dates=['created_utc', 'month', 'year'])\n",
    "reddit_df = reddit_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "358408"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reddit_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>body</th>\n",
       "      <th>controversiality</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>distinguished</th>\n",
       "      <th>downs</th>\n",
       "      <th>gilded</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>score</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>ups</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KineticSolution</td>\n",
       "      <td>what does \"ymmv\" stand for? -  - regarding the...</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-05-01 14:16:52</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>c9qftjc</td>\n",
       "      <td>t1_c9qftjc</td>\n",
       "      <td>t1_c9qflks</td>\n",
       "      <td>0</td>\n",
       "      <td>Conservative</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-05-01</td>\n",
       "      <td>2013-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[deleted]</td>\n",
       "      <td>your mileage may vary. -  - you don't get it. ...</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-05-01 14:31:20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>c9qg631</td>\n",
       "      <td>t1_c9qg631</td>\n",
       "      <td>t1_c9qftjc</td>\n",
       "      <td>1</td>\n",
       "      <td>Conservative</td>\n",
       "      <td>1</td>\n",
       "      <td>2013-05-01</td>\n",
       "      <td>2013-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gunner1868</td>\n",
       "      <td>where'd you find this teaser? curious to watch...</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-07-07 22:00:34</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>cir7sp2</td>\n",
       "      <td>t1_cir7sp2</td>\n",
       "      <td>t1_cir37o7</td>\n",
       "      <td>1</td>\n",
       "      <td>pike</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-07-01</td>\n",
       "      <td>2014-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LostVikingC</td>\n",
       "      <td>https://www.youtube.com/watch?v=ifjsx-7zwkm</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-07-08 10:35:30</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>cirld22</td>\n",
       "      <td>t1_cirld22</td>\n",
       "      <td>t1_cir7sp2</td>\n",
       "      <td>1</td>\n",
       "      <td>pike</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-07-01</td>\n",
       "      <td>2014-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jimmysilverrims</td>\n",
       "      <td>in one instance a culture was about to be dest...</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-05-11 01:17:50</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>c9wm86e</td>\n",
       "      <td>t1_c9wm86e</td>\n",
       "      <td>t1_c9wm2pu</td>\n",
       "      <td>1</td>\n",
       "      <td>DaystromInstitute</td>\n",
       "      <td>1</td>\n",
       "      <td>2013-05-01</td>\n",
       "      <td>2013-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            author                                               body  \\\n",
       "0  KineticSolution  what does \"ymmv\" stand for? -  - regarding the...   \n",
       "1        [deleted]  your mileage may vary. -  - you don't get it. ...   \n",
       "2       gunner1868  where'd you find this teaser? curious to watch...   \n",
       "3      LostVikingC        https://www.youtube.com/watch?v=ifjsx-7zwkm   \n",
       "4  jimmysilverrims  in one instance a culture was about to be dest...   \n",
       "\n",
       "   controversiality         created_utc distinguished downs gilded       id  \\\n",
       "0                 0 2013-05-01 14:16:52             0   0.0      0  c9qftjc   \n",
       "1                 0 2013-05-01 14:31:20             0   0.0      0  c9qg631   \n",
       "2                 0 2014-07-07 22:00:34             0   0.0      0  cir7sp2   \n",
       "3                 0 2014-07-08 10:35:30             0   0.0      0  cirld22   \n",
       "4                 0 2013-05-11 01:17:50             0   0.0      0  c9wm86e   \n",
       "\n",
       "         name   parent_id  score          subreddit ups      month       year  \n",
       "0  t1_c9qftjc  t1_c9qflks      0       Conservative   0 2013-05-01 2013-01-01  \n",
       "1  t1_c9qg631  t1_c9qftjc      1       Conservative   1 2013-05-01 2013-01-01  \n",
       "2  t1_cir7sp2  t1_cir37o7      1               pike   1 2014-07-01 2014-01-01  \n",
       "3  t1_cirld22  t1_cir7sp2      1               pike   1 2014-07-01 2014-01-01  \n",
       "4  t1_c9wm86e  t1_c9wm2pu      1  DaystromInstitute   1 2013-05-01 2013-01-01  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['author', 'body', 'controversiality', 'created_utc', 'distinguished',\n",
       "       'downs', 'gilded', 'id', 'name', 'parent_id', 'score', 'subreddit',\n",
       "       'ups', 'month', 'year'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reddit_df.drop_duplicates(\n",
    "    ['author', 'body', 'controversiality', 'created_utc', 'distinguished',\n",
    "     'gilded', 'id', 'name', 'parent_id', 'subreddit', 'month', 'year'],\n",
    "    inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "358344"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reddit_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reddit_df = reddit_df[reddit_df['author'] != '[deleted]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "338857"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reddit_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "graph = nx.DiGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2h 40min 2s, sys: 7.71 s, total: 2h 40min 9s\n",
      "Wall time: 2h 40min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "unique_names = reddit_df['name'].unique()\n",
    "\n",
    "for i, x in reddit_df.iterrows():\n",
    "    pid = x['parent_id']\n",
    "    if pid in unique_names:\n",
    "        user = x['author']\n",
    "        aux_df = reddit_df[reddit_df['name'] == pid]\n",
    "        aux_sr = aux_df.iloc[0]\n",
    "        p_user = aux_sr['author']\n",
    "        if user != p_user:\n",
    "            if not graph.has_edge(user, p_user):\n",
    "                graph.add_edge(user, p_user, weight=1)\n",
    "            else:\n",
    "                graph[user][p_user]['weight'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136548"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.number_of_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "182127"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.number_of_edges()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nx.write_gexf(graph, 'user_graph.gexf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
